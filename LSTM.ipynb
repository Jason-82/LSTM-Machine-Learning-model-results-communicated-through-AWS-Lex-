{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import alpaca_trade_api as tradeapi\n",
    "from datetime import date\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = \"your_alpaca_apikey\"\n",
    "alpaca_secret_key = \"your_alpaca_secretkey\"\n",
    "\n",
    "# Create the Alpaca API object\n",
    "api = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset your tickers, then pull returns data:\n",
    "# Set the ticker\n",
    "ticker = ['SPY', 'AGG','DIA', 'XLY','QQQ', 'GLD', 'SLV', 'VWO','USO', 'EFA']\n",
    "\n",
    "# Set timeframe to '1D'\n",
    "timeframe = \"1D\"\n",
    "\n",
    "# Set start and end datetimes of 1 year, between now and 365 days ago.\n",
    "start_date = pd.Timestamp('2015-01-01', tz='America/New_York').isoformat()\n",
    "today = date.today()\n",
    "end_date = pd.Timestamp(today.strftime(\"%Y-%m-%d\"), tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Get 1 year's worth of historical data for SPY and AGG\n",
    "df = api.get_barset(\n",
    "    ticker,\n",
    "    timeframe,\n",
    "    limit=None,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    after=None,\n",
    "    until=None,\n",
    ").df\n",
    "\n",
    "\n",
    "# Remove the time component of the data\n",
    "df.index = df.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(\n",
    "    columns=['open', 'high', 'low', 'volume'],\n",
    "    level=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>AGG</th>\n",
       "      <th>DIA</th>\n",
       "      <th>EFA</th>\n",
       "      <th>GLD</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SLV</th>\n",
       "      <th>SPY</th>\n",
       "      <th>USO</th>\n",
       "      <th>VWO</th>\n",
       "      <th>XLY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-06</th>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.012818</td>\n",
       "      <td>0.071828</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.004947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07</th>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.015734</td>\n",
       "      <td>-0.011235</td>\n",
       "      <td>-0.025316</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.011262</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>0.001641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-10</th>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>-0.003354</td>\n",
       "      <td>-0.004494</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.011682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-11</th>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>-0.053534</td>\n",
       "      <td>-0.018758</td>\n",
       "      <td>-0.135926</td>\n",
       "      <td>-0.008136</td>\n",
       "      <td>-0.010942</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>-0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12</th>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.022160</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>0.025338</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.013821</td>\n",
       "      <td>0.024304</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.013118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AGG       DIA       EFA       GLD       QQQ       SLV  \\\n",
       "               close     close     close     close     close     close   \n",
       "2020-08-06  0.001508  0.007021  0.001410  0.013065  0.012818  0.071828   \n",
       "2020-08-07 -0.001129  0.002373 -0.004381 -0.015734 -0.011235 -0.025316   \n",
       "2020-08-10 -0.000963  0.013110  0.003300 -0.003354 -0.004494  0.031322   \n",
       "2020-08-11 -0.002891 -0.003702  0.003759 -0.053534 -0.018758 -0.135926   \n",
       "2020-08-12 -0.001891  0.010246  0.022160 -0.004667  0.025338  0.002992   \n",
       "\n",
       "                 SPY       USO       VWO       XLY  \n",
       "               close     close     close     close  \n",
       "2020-08-06  0.006776 -0.001323  0.001808  0.004947  \n",
       "2020-08-07  0.000718 -0.011262 -0.020523  0.001641  \n",
       "2020-08-10  0.002989  0.010385  0.000230  0.011682  \n",
       "2020-08-11 -0.008136 -0.010942 -0.004144 -0.001690  \n",
       "2020-08-12  0.013821  0.024304  0.012483  0.013118  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating daily returns\n",
    "daily_returns=df.pct_change()\n",
    "daily_returns = daily_returns.dropna()\n",
    "daily_returns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns.columns = daily_returns.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGG</th>\n",
       "      <th>DIA</th>\n",
       "      <th>EFA</th>\n",
       "      <th>GLD</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SLV</th>\n",
       "      <th>SPY</th>\n",
       "      <th>USO</th>\n",
       "      <th>VWO</th>\n",
       "      <th>XLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-06</th>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.012818</td>\n",
       "      <td>0.071828</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.004947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07</th>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.015734</td>\n",
       "      <td>-0.011235</td>\n",
       "      <td>-0.025316</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.011262</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>0.001641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-10</th>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>-0.003354</td>\n",
       "      <td>-0.004494</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.011682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-11</th>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>-0.053534</td>\n",
       "      <td>-0.018758</td>\n",
       "      <td>-0.135926</td>\n",
       "      <td>-0.008136</td>\n",
       "      <td>-0.010942</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>-0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12</th>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.022160</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>0.025338</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.013821</td>\n",
       "      <td>0.024304</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.013118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AGG       DIA       EFA       GLD       QQQ       SLV  \\\n",
       "2020-08-06  0.001508  0.007021  0.001410  0.013065  0.012818  0.071828   \n",
       "2020-08-07 -0.001129  0.002373 -0.004381 -0.015734 -0.011235 -0.025316   \n",
       "2020-08-10 -0.000963  0.013110  0.003300 -0.003354 -0.004494  0.031322   \n",
       "2020-08-11 -0.002891 -0.003702  0.003759 -0.053534 -0.018758 -0.135926   \n",
       "2020-08-12 -0.001891  0.010246  0.022160 -0.004667  0.025338  0.002992   \n",
       "\n",
       "                 SPY       USO       VWO       XLY  \n",
       "2020-08-06  0.006776 -0.001323  0.001808  0.004947  \n",
       "2020-08-07  0.000718 -0.011262 -0.020523  0.001641  \n",
       "2020-08-10  0.002989  0.010385  0.000230  0.011682  \n",
       "2020-08-11 -0.008136 -0.010942 -0.004144 -0.001690  \n",
       "2020-08-12  0.013821  0.024304  0.012483  0.013118  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_returns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to chunk the data\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 200\n",
    "\n",
    "feature_column1 = 0 \n",
    "target_column1 = 0  \n",
    "X1, y1 = window_data(daily_returns, window_size, feature_column1, target_column1)\n",
    "#print (f\"X1 sample values:{X[:5]}\")\n",
    "#print (f\"y1 sample values:{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "\n",
    "feature_column2 = 1 \n",
    "feature_column3 = 2 \n",
    "feature_column4 = 3 \n",
    "feature_column5 = 4 \n",
    "feature_column6 = 5 \n",
    "feature_column7 = 6 \n",
    "feature_column8 = 7 \n",
    "feature_column9 = 8 \n",
    "feature_column10 = 9 \n",
    "\n",
    "target_column2 = 1  \n",
    "target_column3 = 2\n",
    "target_column4 = 3\n",
    "target_column5 = 4\n",
    "target_column6 = 5\n",
    "target_column7 = 6\n",
    "target_column8 = 7\n",
    "target_column9 = 8\n",
    "target_column10 = 9\n",
    "\n",
    "X2, y2 = window_data(daily_returns, window_size, feature_column2, target_column2)\n",
    "X3, y3 = window_data(daily_returns, window_size, feature_column3, target_column3)\n",
    "X4, y4 = window_data(daily_returns, window_size, feature_column4, target_column4)\n",
    "X5, y5 = window_data(daily_returns, window_size, feature_column5, target_column5)\n",
    "X6, y6 = window_data(daily_returns, window_size, feature_column6, target_column6)\n",
    "X7, y7 = window_data(daily_returns, window_size, feature_column7, target_column7)\n",
    "X8, y8 = window_data(daily_returns, window_size, feature_column8, target_column8)\n",
    "X9, y9 = window_data(daily_returns, window_size, feature_column9, target_column9)\n",
    "X10, y10 = window_data(daily_returns, window_size, feature_column10, target_column10)\n",
    "#print (f\"X3 sample values:{X[:5]}\")\n",
    "#print (f\"y3 sample values:{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "# Use last 5 days for testing\n",
    "#split = int(0.7 * len(X))\n",
    "X_train1 = X1[:-5]\n",
    "X_train2 = X2[:-5]\n",
    "X_train3 = X3[:-5]\n",
    "X_train4 = X4[:-5]\n",
    "X_train5 = X5[:-5]\n",
    "X_train6 = X6[:-5]\n",
    "X_train7 = X7[:-5]\n",
    "X_train8 = X8[:-5]\n",
    "X_train9 = X9[:-5]\n",
    "X_train10 = X10[:-5]\n",
    "\n",
    "X_test1 = X1[-5:]\n",
    "X_test2 = X2[-5:]\n",
    "X_test3 = X3[-5:]\n",
    "X_test4 = X4[-5:]\n",
    "X_test5 = X5[-5:]\n",
    "X_test6 = X6[-5:]\n",
    "X_test7 = X7[-5:]\n",
    "X_test8 = X8[-5:]\n",
    "X_test9 = X9[-5:]\n",
    "X_test10 = X10[-5:]\n",
    "\n",
    "y_train1 = y1[:-5]\n",
    "y_train2 = y2[:-5]\n",
    "y_train3 = y3[:-5]\n",
    "y_train4 = y4[:-5]\n",
    "y_train5 = y5[:-5]\n",
    "y_train6 = y6[:-5]\n",
    "y_train7 = y7[:-5]\n",
    "y_train8 = y8[:-5]\n",
    "y_train9 = y9[:-5]\n",
    "y_train10 = y10[:-5]\n",
    "\n",
    "y_test1 = y1[-5:]\n",
    "y_test2 = y2[-5:]\n",
    "y_test3 = y3[-5:]\n",
    "y_test4 = y4[-5:]\n",
    "y_test5 = y5[-5:]\n",
    "y_test6 = y6[-5:]\n",
    "y_test7 = y7[-5:]\n",
    "y_test8 = y8[-5:]\n",
    "y_test9 = y9[-5:]\n",
    "y_test10 = y10[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X1)\n",
    "scaler.fit(X2)\n",
    "scaler.fit(X3)\n",
    "scaler.fit(X4)\n",
    "scaler.fit(X5)\n",
    "scaler.fit(X6)\n",
    "scaler.fit(X7)\n",
    "scaler.fit(X8)\n",
    "scaler.fit(X9)\n",
    "scaler.fit(X10)\n",
    "\n",
    "X_train1 = scaler.transform(X_train1)\n",
    "X_train2 = scaler.transform(X_train2)\n",
    "X_train3 = scaler.transform(X_train3)\n",
    "X_train4 = scaler.transform(X_train4)\n",
    "X_train5 = scaler.transform(X_train5)\n",
    "X_train6 = scaler.transform(X_train6)\n",
    "X_train7 = scaler.transform(X_train7)\n",
    "X_train8 = scaler.transform(X_train8)\n",
    "X_train9 = scaler.transform(X_train9)\n",
    "X_train10 = scaler.transform(X_train10)\n",
    "\n",
    "X_test1 = scaler.transform(X_test1)\n",
    "X_test2 = scaler.transform(X_test2)\n",
    "X_test3 = scaler.transform(X_test3)\n",
    "X_test4 = scaler.transform(X_test4)\n",
    "X_test5 = scaler.transform(X_test5)\n",
    "X_test6 = scaler.transform(X_test6)\n",
    "X_test7 = scaler.transform(X_test7)\n",
    "X_test8 = scaler.transform(X_test8)\n",
    "X_test9 = scaler.transform(X_test9)\n",
    "X_test10 = scaler.transform(X_test10)\n",
    "\n",
    "scaler.fit(y1)\n",
    "scaler.fit(y2)\n",
    "scaler.fit(y3)\n",
    "scaler.fit(y4)\n",
    "scaler.fit(y5)\n",
    "scaler.fit(y6)\n",
    "scaler.fit(y7)\n",
    "scaler.fit(y8)\n",
    "scaler.fit(y9)\n",
    "scaler.fit(y10)\n",
    "\n",
    "y_train1 = scaler.transform(y_train1)\n",
    "y_train2 = scaler.transform(y_train2)\n",
    "y_train3 = scaler.transform(y_train3)\n",
    "y_train4 = scaler.transform(y_train4)\n",
    "y_train5 = scaler.transform(y_train5)\n",
    "y_train6 = scaler.transform(y_train6)\n",
    "y_train7 = scaler.transform(y_train7)\n",
    "y_train8 = scaler.transform(y_train8)\n",
    "y_train9 = scaler.transform(y_train9)\n",
    "y_train10 = scaler.transform(y_train10)\n",
    "\n",
    "y_test1 = scaler.transform(y_test1)\n",
    "y_test2 = scaler.transform(y_test2)\n",
    "y_test3 = scaler.transform(y_test3)\n",
    "y_test4 = scaler.transform(y_test4)\n",
    "y_test5 = scaler.transform(y_test5)\n",
    "y_test6 = scaler.transform(y_test6)\n",
    "y_test7 = scaler.transform(y_test7)\n",
    "y_test8 = scaler.transform(y_test8)\n",
    "y_test9 = scaler.transform(y_test9)\n",
    "y_test10 = scaler.transform(y_test10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "X_train1 = X_train1.reshape((X_train1.shape[0], X_train1.shape[1], 1))\n",
    "X_train2 = X_train2.reshape((X_train2.shape[0], X_train2.shape[1], 1))\n",
    "X_train3 = X_train3.reshape((X_train3.shape[0], X_train3.shape[1], 1))\n",
    "X_train4 = X_train4.reshape((X_train4.shape[0], X_train4.shape[1], 1))\n",
    "X_train5 = X_train5.reshape((X_train5.shape[0], X_train5.shape[1], 1))\n",
    "X_train6 = X_train6.reshape((X_train6.shape[0], X_train6.shape[1], 1))\n",
    "X_train7 = X_train7.reshape((X_train7.shape[0], X_train7.shape[1], 1))\n",
    "X_train8 = X_train8.reshape((X_train8.shape[0], X_train8.shape[1], 1))\n",
    "X_train9 = X_train9.reshape((X_train9.shape[0], X_train9.shape[1], 1))\n",
    "X_train10 = X_train10.reshape((X_train10.shape[0], X_train10.shape[1], 1))\n",
    "\n",
    "X_test1 = X_test1.reshape((X_test1.shape[0], X_test1.shape[1], 1))\n",
    "X_test2 = X_test2.reshape((X_test2.shape[0], X_test2.shape[1], 1))\n",
    "X_test3 = X_test3.reshape((X_test3.shape[0], X_test3.shape[1], 1))\n",
    "X_test4 = X_test4.reshape((X_test4.shape[0], X_test4.shape[1], 1))\n",
    "X_test5 = X_test5.reshape((X_test5.shape[0], X_test5.shape[1], 1))\n",
    "X_test6 = X_test6.reshape((X_test6.shape[0], X_test6.shape[1], 1))\n",
    "X_test7 = X_test7.reshape((X_test7.shape[0], X_test7.shape[1], 1))\n",
    "X_test8 = X_test8.reshape((X_test8.shape[0], X_test8.shape[1], 1))\n",
    "X_test9 = X_test9.reshape((X_test9.shape[0], X_test9.shape[1], 1))\n",
    "X_test10 = X_test10.reshape((X_test10.shape[0], X_test10.shape[1], 1))\n",
    "#print (f\"X_train2 sample values:\\n{X_train2[:5]} \\n\")\n",
    "#print (f\"X_test2 sample values:\\n{X_test2[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train LSTM RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model1 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model1.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train1.shape[1], 1))\n",
    "    )\n",
    "model1.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model1.add(LSTM(units=number_units, return_sequences=True))\n",
    "model1.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model1.add(LSTM(units=number_units, return_sequences=True))\n",
    "model1.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model1.add(LSTM(units=number_units))\n",
    "model1.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model1.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model2.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train2.shape[1], 1))\n",
    "    )\n",
    "model2.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model2.add(LSTM(units=number_units, return_sequences=True))\n",
    "model2.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model2.add(LSTM(units=number_units, return_sequences=True))\n",
    "model2.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model2.add(LSTM(units=number_units))\n",
    "model2.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model2.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model3.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train3.shape[1], 1))\n",
    "    )\n",
    "model3.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model3.add(LSTM(units=number_units, return_sequences=True))\n",
    "model3.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model3.add(LSTM(units=number_units, return_sequences=True))\n",
    "model3.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model3.add(LSTM(units=number_units))\n",
    "model3.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model3.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model4.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train4.shape[1], 1))\n",
    "    )\n",
    "model4.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model4.add(LSTM(units=number_units, return_sequences=True))\n",
    "model4.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model4.add(LSTM(units=number_units, return_sequences=True))\n",
    "model4.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model4.add(LSTM(units=number_units))\n",
    "model4.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model4.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model5.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train5.shape[1], 1))\n",
    "    )\n",
    "model5.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model5.add(LSTM(units=number_units, return_sequences=True))\n",
    "model5.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model5.add(LSTM(units=number_units, return_sequences=True))\n",
    "model5.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model5.add(LSTM(units=number_units))\n",
    "model5.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model5.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model6.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train6.shape[1], 1))\n",
    "    )\n",
    "model6.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model6.add(LSTM(units=number_units, return_sequences=True))\n",
    "model6.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model6.add(LSTM(units=number_units, return_sequences=True))\n",
    "model6.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model6.add(LSTM(units=number_units))\n",
    "model6.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model6.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model7.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train7.shape[1], 1))\n",
    "    )\n",
    "model7.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model7.add(LSTM(units=number_units, return_sequences=True))\n",
    "model7.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model7.add(LSTM(units=number_units, return_sequences=True))\n",
    "model7.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model7.add(LSTM(units=number_units))\n",
    "model7.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model7.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model8.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train8.shape[1], 1))\n",
    "    )\n",
    "model8.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model8.add(LSTM(units=number_units, return_sequences=True))\n",
    "model8.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model8.add(LSTM(units=number_units, return_sequences=True))\n",
    "model8.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model8.add(LSTM(units=number_units))\n",
    "model8.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model8.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model9.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train9.shape[1], 1))\n",
    "    )\n",
    "model9.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model9.add(LSTM(units=number_units, return_sequences=True))\n",
    "model9.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model9.add(LSTM(units=number_units, return_sequences=True))\n",
    "model9.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model9.add(LSTM(units=number_units))\n",
    "model9.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model9.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = Sequential()\n",
    "\n",
    "number_units = 200\n",
    "dropout_fraction = 0.00000000002\n",
    "\n",
    "# Layer 1\n",
    "model10.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train10.shape[1], 1))\n",
    "    )\n",
    "model10.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model10.add(LSTM(units=number_units, return_sequences=True))\n",
    "model10.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model10.add(LSTM(units=number_units, return_sequences=True))\n",
    "model10.add(Dropout(dropout_fraction))\n",
    "# Layer 4\n",
    "model10.add(LSTM(units=number_units))\n",
    "model10.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model10.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model1.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model2.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model3.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model4.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model5.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model6.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model7.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model8.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model9.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model10.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 43s 357ms/step - loss: 0.0090\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 63s 522ms/step - loss: 2.2298e-04\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 67s 555ms/step - loss: 2.3229e-04\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 2.5751e-04\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 66s 549ms/step - loss: 2.6362e-04\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 68s 562ms/step - loss: 2.6761e-04\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 70s 575ms/step - loss: 2.7600e-04\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 73s 607ms/step - loss: 2.8304e-04\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 75s 621ms/step - loss: 2.8657e-04\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 78s 642ms/step - loss: 2.8770e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4cba9db50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model1.fit(X_train1, y_train1, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 54s 448ms/step - loss: 0.0175\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 67s 553ms/step - loss: 0.0114\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 72s 599ms/step - loss: 0.0114\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 77s 636ms/step - loss: 0.0114\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 78s 645ms/step - loss: 0.0113\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 79s 655ms/step - loss: 0.0113\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 80s 658ms/step - loss: 0.0112\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 78s 644ms/step - loss: 0.0112\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 65s 533ms/step - loss: 0.0112\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 64s 527ms/step - loss: 0.0112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4d7cf0d00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train2, y_train2, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 45s 372ms/step - loss: 0.0298\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 52s 429ms/step - loss: 0.0185\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 57s 471ms/step - loss: 0.0186\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 60s 493ms/step - loss: 0.0186\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 60s 494ms/step - loss: 0.0186\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 64s 532ms/step - loss: 0.0186\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 63s 524ms/step - loss: 0.0185\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 61s 505ms/step - loss: 0.0185\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 63s 520ms/step - loss: 0.0185\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 64s 527ms/step - loss: 0.0185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4e2e7c880>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train3, y_train3, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 50s 410ms/step - loss: 0.0114\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 58s 477ms/step - loss: 0.0017\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 61s 502ms/step - loss: 0.0017\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 61s 507ms/step - loss: 0.0018\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 62s 513ms/step - loss: 0.0018\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 61s 507ms/step - loss: 0.0018\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 62s 511ms/step - loss: 0.0017\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 61s 508ms/step - loss: 0.0017\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 65s 534ms/step - loss: 0.0017\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 61s 504ms/step - loss: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4ee242310>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train4, y_train4, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 54s 446ms/step - loss: 0.0198\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 58s 482ms/step - loss: 0.0042\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 59s 484ms/step - loss: 0.0042\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 59s 486ms/step - loss: 0.0042\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 59s 488ms/step - loss: 0.0042\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 60s 493ms/step - loss: 0.0042\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 59s 487ms/step - loss: 0.0042\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 59s 487ms/step - loss: 0.0042\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 60s 494ms/step - loss: 0.0042\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 59s 487ms/step - loss: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4f9440c40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train5, y_train5, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 38s 316ms/step - loss: 0.0195\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 56s 463ms/step - loss: 0.0051\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 59s 486ms/step - loss: 0.0051\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 63s 519ms/step - loss: 0.0051\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 61s 502ms/step - loss: 0.0051\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 61s 507ms/step - loss: 0.0050\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 61s 504ms/step - loss: 0.0050\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 61s 503ms/step - loss: 0.0049\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 62s 510ms/step - loss: 0.0049\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 67s 556ms/step - loss: 0.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b507c739d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(X_train6, y_train6, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 69s 574ms/step - loss: 0.0195\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 61s 502ms/step - loss: 0.0033\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 67s 555ms/step - loss: 0.0033\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 65s 535ms/step - loss: 0.0033\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 70s 580ms/step - loss: 0.0033\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 66s 545ms/step - loss: 0.0033\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 69s 573ms/step - loss: 0.0033\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 68s 559ms/step - loss: 0.0033\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 70s 576ms/step - loss: 0.0033\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 65s 536ms/step - loss: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b512e922e0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit(X_train7, y_train7, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 56s 459ms/step - loss: 0.9534\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 66s 543ms/step - loss: 0.9400\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 68s 565ms/step - loss: 0.9359\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 73s 607ms/step - loss: 0.9336\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 76s 630ms/step - loss: 0.9329\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 66s 544ms/step - loss: 0.9321\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 66s 546ms/step - loss: 0.9312\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 0.9310\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 65s 533ms/step - loss: 0.9306\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 65s 535ms/step - loss: 0.9313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b51dfcba90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.fit(X_train8, y_train8, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 46s 383ms/step - loss: 0.0099\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 63s 521ms/step - loss: 0.0043\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 61s 506ms/step - loss: 0.0043\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 64s 525ms/step - loss: 0.0042\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 64s 529ms/step - loss: 0.0042\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 61s 504ms/step - loss: 0.0041\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 61s 505ms/step - loss: 0.0041\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 65s 539ms/step - loss: 0.0042\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 63s 517ms/step - loss: 0.0043\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 62s 513ms/step - loss: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5291bf940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9.fit(X_train9, y_train9, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 63s 521ms/step - loss: 0.0142\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 67s 554ms/step - loss: 0.0037\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 70s 579ms/step - loss: 0.0037\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 70s 582ms/step - loss: 0.0037\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 70s 577ms/step - loss: 0.0037\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 66s 542ms/step - loss: 0.0037\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 70s 580ms/step - loss: 0.0037\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 0.0036\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 64s 530ms/step - loss: 0.0036\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 63s 520ms/step - loss: 0.0036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5347d96a0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10.fit(X_train10, y_train10, epochs=10, shuffle=False, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B5481CCC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B549D989D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B54BBCD790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B54E75B5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B55031A5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B552EBB3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "predicted1= model1.predict(X_test1)\n",
    "predicted2= model2.predict(X_test2)\n",
    "predicted3= model3.predict(X_test3)\n",
    "predicted4= model4.predict(X_test4)\n",
    "predicted5= model5.predict(X_test5)\n",
    "predicted6= model6.predict(X_test6)\n",
    "predicted7= model7.predict(X_test7)\n",
    "predicted8= model8.predict(X_test8)\n",
    "predicted9= model9.predict(X_test9)\n",
    "predicted10= model10.predict(X_test10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58662635],\n",
       "       [0.58676094],\n",
       "       [0.5869585 ],\n",
       "       [0.58722144],\n",
       "       [0.5874878 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_returns1 = scaler.inverse_transform(predicted1)\n",
    "predicted_returns2 = scaler.inverse_transform(predicted2)\n",
    "predicted_returns3 = scaler.inverse_transform(predicted3)\n",
    "predicted_returns4 = scaler.inverse_transform(predicted4)\n",
    "predicted_returns5 = scaler.inverse_transform(predicted5)\n",
    "predicted_returns6 = scaler.inverse_transform(predicted6)\n",
    "predicted_returns7 = scaler.inverse_transform(predicted7)\n",
    "predicted_returns8 = scaler.inverse_transform(predicted8)\n",
    "predicted_returns9 = scaler.inverse_transform(predicted9)\n",
    "predicted_returns10 = scaler.inverse_transform(predicted10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_agg=pd.DataFrame((predicted_returns1 + 1)).prod()\n",
    "forecast_dia=pd.DataFrame((predicted_returns2 + 1)).prod()\n",
    "forecast_efa=pd.DataFrame((predicted_returns3 + 1)).prod()\n",
    "forecast_gld=pd.DataFrame((predicted_returns4 + 1)).prod()\n",
    "forecast_qqq=pd.DataFrame((predicted_returns5 + 1)).prod()\n",
    "forecast_slv=pd.DataFrame((predicted_returns6 + 1)).prod()\n",
    "forecast_spy=pd.DataFrame((predicted_returns7 + 1)).prod()\n",
    "forecast_uso=pd.DataFrame((predicted_returns8 + 1)).prod()\n",
    "forecast_vwo=pd.DataFrame((predicted_returns9 + 1)).prod()\n",
    "forecast_xly=pd.DataFrame((predicted_returns10 + 1)).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_agg = pd.DataFrame(forecast_agg)\n",
    "forecast_dia=pd.DataFrame(forecast_dia)\n",
    "forecast_efa=pd.DataFrame(forecast_efa)\n",
    "forecast_gld=pd.DataFrame(forecast_gld)\n",
    "forecast_qqq=pd.DataFrame(forecast_qqq)\n",
    "forecast_slv=pd.DataFrame(forecast_slv)\n",
    "forecast_spy=pd.DataFrame(forecast_spy)\n",
    "forecast_uso=pd.DataFrame(forecast_uso)\n",
    "forecast_vwo=pd.DataFrame(forecast_vwo)\n",
    "forecast_xly=pd.DataFrame(forecast_xly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_agg['Return_Forecast_AGG']=forecast_agg[0]\n",
    "forecast_dia['Return_Forecast_DIA']=forecast_dia[0]\n",
    "forecast_efa['Return_Forecast_EFA']=forecast_efa[0]\n",
    "forecast_gld['Return_Forecast_GLD']=forecast_gld[0]\n",
    "forecast_qqq['Return_Forecast_QQQ']=forecast_qqq[0]\n",
    "forecast_slv['Return_Forecast_SLV']=forecast_slv[0]\n",
    "forecast_spy['Return_Forecast_SPY']=forecast_spy[0]\n",
    "forecast_uso['Return_Forecast_USO']=forecast_uso[0]\n",
    "forecast_vwo['Return_Forecast_VWO']=forecast_vwo[0]\n",
    "forecast_xly['Return_Forecast_XLY']=forecast_xly[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_agg = forecast_agg.drop(columns=[0])\n",
    "forecast_dia = forecast_dia.drop(columns=[0])\n",
    "forecast_efa = forecast_efa.drop(columns=[0])\n",
    "forecast_gld = forecast_gld.drop(columns=[0])\n",
    "forecast_qqq = forecast_qqq.drop(columns=[0])\n",
    "forecast_slv = forecast_slv.drop(columns=[0])\n",
    "forecast_spy = forecast_spy.drop(columns=[0])\n",
    "forecast_uso = forecast_uso.drop(columns=[0])\n",
    "forecast_vwo = forecast_vwo.drop(columns=[0])\n",
    "forecast_xly = forecast_xly.drop(columns=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = pd.concat([forecast_agg,forecast_dia,forecast_efa,forecast_gld,forecast_qqq,forecast_slv,forecast_spy,forecast_uso,forecast_vwo,forecast_xly],axis=\"columns\", join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return_Forecast_AGG</th>\n",
       "      <th>Return_Forecast_DIA</th>\n",
       "      <th>Return_Forecast_EFA</th>\n",
       "      <th>Return_Forecast_GLD</th>\n",
       "      <th>Return_Forecast_QQQ</th>\n",
       "      <th>Return_Forecast_SLV</th>\n",
       "      <th>Return_Forecast_SPY</th>\n",
       "      <th>Return_Forecast_USO</th>\n",
       "      <th>Return_Forecast_VWO</th>\n",
       "      <th>Return_Forecast_XLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.020094</td>\n",
       "      <td>1.017355</td>\n",
       "      <td>0.998162</td>\n",
       "      <td>1.023484</td>\n",
       "      <td>1.01581</td>\n",
       "      <td>1.096069</td>\n",
       "      <td>0.996697</td>\n",
       "      <td>1.215405</td>\n",
       "      <td>1.043718</td>\n",
       "      <td>1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Return_Forecast_AGG  Return_Forecast_DIA  Return_Forecast_EFA  \\\n",
       "0             1.020094             1.017355             0.998162   \n",
       "\n",
       "   Return_Forecast_GLD  Return_Forecast_QQQ  Return_Forecast_SLV  \\\n",
       "0             1.023484              1.01581             1.096069   \n",
       "\n",
       "   Return_Forecast_SPY  Return_Forecast_USO  Return_Forecast_VWO  \\\n",
       "0             0.996697             1.215405             1.043718   \n",
       "\n",
       "   Return_Forecast_XLY  \n",
       "0               1.0215  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_AGG</th>\n",
       "      <td>1.020094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_DIA</th>\n",
       "      <td>1.017355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_EFA</th>\n",
       "      <td>0.998162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_GLD</th>\n",
       "      <td>1.023484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_QQQ</th>\n",
       "      <td>1.015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_SLV</th>\n",
       "      <td>1.096069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_SPY</th>\n",
       "      <td>0.996697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_USO</th>\n",
       "      <td>1.215405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_VWO</th>\n",
       "      <td>1.043718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_XLY</th>\n",
       "      <td>1.021500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "Return_Forecast_AGG  1.020094\n",
       "Return_Forecast_DIA  1.017355\n",
       "Return_Forecast_EFA  0.998162\n",
       "Return_Forecast_GLD  1.023484\n",
       "Return_Forecast_QQQ  1.015810\n",
       "Return_Forecast_SLV  1.096069\n",
       "Return_Forecast_SPY  0.996697\n",
       "Return_Forecast_USO  1.215405\n",
       "Return_Forecast_VWO  1.043718\n",
       "Return_Forecast_XLY  1.021500"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm=portfolio.T\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_USO</th>\n",
       "      <td>1.215405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_SLV</th>\n",
       "      <td>1.096069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_VWO</th>\n",
       "      <td>1.043718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_GLD</th>\n",
       "      <td>1.023484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_XLY</th>\n",
       "      <td>1.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_AGG</th>\n",
       "      <td>1.020094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_DIA</th>\n",
       "      <td>1.017355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_QQQ</th>\n",
       "      <td>1.015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_EFA</th>\n",
       "      <td>0.998162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_Forecast_SPY</th>\n",
       "      <td>0.996697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "Return_Forecast_USO  1.215405\n",
       "Return_Forecast_SLV  1.096069\n",
       "Return_Forecast_VWO  1.043718\n",
       "Return_Forecast_GLD  1.023484\n",
       "Return_Forecast_XLY  1.021500\n",
       "Return_Forecast_AGG  1.020094\n",
       "Return_Forecast_DIA  1.017355\n",
       "Return_Forecast_QQQ  1.015810\n",
       "Return_Forecast_EFA  0.998162\n",
       "Return_Forecast_SPY  0.996697"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = lstm.sort_values(by=[0],ascending=False)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.to_csv('lstm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
